{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from ALPackage.transformer import Transformer, TransformerAL\n",
    "from utils import get_word_vector, get_nlp_data, set_device\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, dataset, max_len, min_len = 1):\n",
    "        self.dataset = dataset\n",
    "        self.class_num = None\n",
    "        self.batch_size = 256        \n",
    "        self.max_len = max_len\n",
    "        self.min_len = min_len\n",
    "        self.vocab_size = 30000\n",
    "        self.pretrained_embedding = None\n",
    "        self.embedding_dim = 300\n",
    "        self.x_hid = 256\n",
    "        self.y_hid = 128\n",
    "        self.n_heads = 6\n",
    "        self.n_layers = 1        \n",
    "        self.dropout = 0.3\n",
    "        self.lr = 0.00025\n",
    "        self.epochs = 10\n",
    "        self.act = nn.Tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|========================= Load data:dbpedia_14 =====================================================|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset dbpedia_14 (/home/u3933826/.cache/huggingface/datasets/dbpedia_14/dbpedia_14/2.0.0/01dab9e10d969eadcdbc918be5a09c9190a24caeae33b10eee8f367a1e3f1f0c)\n",
      "Found cached dataset dbpedia_14 (/home/u3933826/.cache/huggingface/datasets/dbpedia_14/dbpedia_14/2.0.0/01dab9e10d969eadcdbc918be5a09c9190a24caeae33b10eee8f367a1e3f1f0c)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|========================= Preprocessing ============================================================|\n",
      "Original Data: 560000\n",
      "Valid Data: 559967\n",
      "total count words 887879\n",
      "vocab size 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading glove vocabs...: 100%|██████████| 400000/400000 [00:05<00:00, 70505.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 28354 words in glove\n"
     ]
    }
   ],
   "source": [
    "dataset = 'dbpedia_14'\n",
    "args = Args(dataset, 128)\n",
    "train_loader, test_loader, class_num, vocab = get_nlp_data(args)\n",
    "args.class_num = class_num\n",
    "args.pretrained_embedding = get_word_vector(vocab, 'glove')\n",
    "x, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-03-28 09:23:50 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:23:51 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:23:51 108:108 output_json.cpp:417] Completed Stage: Post Processing\n",
      "STAGE:2023-03-28 09:23:51 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:23:51 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:23:52 108:108 output_json.cpp:417] Completed Stage: Post Processing\n",
      "STAGE:2023-03-28 09:23:52 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:23:52 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:23:52 108:108 output_json.cpp:417] Completed Stage: Post Processing\n",
      "STAGE:2023-03-28 09:23:52 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:23:52 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:23:52 108:108 output_json.cpp:417] Completed Stage: Post Processing\n",
      "STAGE:2023-03-28 09:23:52 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:23:52 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:23:53 108:108 output_json.cpp:417] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(args.vocab_size, args.embedding_dim, args.x_hid, args.class_num, args.n_heads, args.n_layers, args.dropout, args.pretrained_embedding)\n",
    "set_device(model, [\"cuda:0\",\"cuda:1\",\"cuda:2\",\"cuda:3\",\"cuda:3\"])\n",
    "optimizer = torch.optim.Adam(model.parameters(), args.lr)\n",
    "loss_fn = nn.NLLLoss()\n",
    "for _ in range(5):\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
    "        with record_function(\"forward\"):\n",
    "            out = model(x)\n",
    "        with record_function(\"backward\"):\n",
    "            loss = loss_fn(out, y.to('cuda:3'))\n",
    "            loss.backward()\n",
    "        with record_function(\"update\"):\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "    prof.export_chrome_trace(f\"{dataset}_BP.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerAL(args.vocab_size, args.embedding_dim, args.x_hid, args.class_num, args.y_hid, args.act, args.lr, args.n_heads, args.n_layers, args.dropout, args.pretrained_embedding)\n",
    "set_device(model, ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-03-28 09:24:15 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:24:15 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:24:16 108:108 output_json.cpp:417] Completed Stage: Post Processing\n",
      "STAGE:2023-03-28 09:24:16 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:24:16 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:24:16 108:108 output_json.cpp:417] Completed Stage: Post Processing\n",
      "STAGE:2023-03-28 09:24:16 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:24:16 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:24:16 108:108 output_json.cpp:417] Completed Stage: Post Processing\n",
      "STAGE:2023-03-28 09:24:16 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:24:16 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:24:17 108:108 output_json.cpp:417] Completed Stage: Post Processing\n",
      "STAGE:2023-03-28 09:24:17 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:24:17 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:24:17 108:108 output_json.cpp:417] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
    "        with record_function(\"forward\"):\n",
    "            model(x, torch.nn.functional.one_hot(y, args.class_num).float())\n",
    "        with record_function(\"backward\"):\n",
    "            model.backward()\n",
    "        with record_function(\"update\"):\n",
    "            model.update()\n",
    "    prof.export_chrome_trace(f\"{dataset}_AL.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-03-28 09:24:21 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:24:21 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:24:21 108:108 output_json.cpp:417] Completed Stage: Post Processing\n",
      "STAGE:2023-03-28 09:24:21 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:24:21 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:24:22 108:108 output_json.cpp:417] Completed Stage: Post Processing\n",
      "STAGE:2023-03-28 09:24:22 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:24:22 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:24:22 108:108 output_json.cpp:417] Completed Stage: Post Processing\n",
      "STAGE:2023-03-28 09:24:22 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:24:22 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:24:22 108:108 output_json.cpp:417] Completed Stage: Post Processing\n",
      "STAGE:2023-03-28 09:24:22 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:24:22 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:24:22 108:108 output_json.cpp:417] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
    "        with record_function(\"forward\"):\n",
    "            model(x, torch.nn.functional.one_hot(y, args.class_num).float())\n",
    "        model.record_thread_backward_and_update()\n",
    "    prof.export_chrome_trace(f\"{dataset}_AL_M.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-03-28 09:24:25 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:24:25 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:24:25 108:108 output_json.cpp:417] Completed Stage: Post Processing\n",
      "STAGE:2023-03-28 09:24:25 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:24:25 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:24:26 108:108 output_json.cpp:417] Completed Stage: Post Processing\n",
      "STAGE:2023-03-28 09:24:26 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:24:26 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:24:26 108:108 output_json.cpp:417] Completed Stage: Post Processing\n",
      "STAGE:2023-03-28 09:24:26 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:24:26 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:24:26 108:108 output_json.cpp:417] Completed Stage: Post Processing\n",
      "STAGE:2023-03-28 09:24:26 108:108 ActivityProfilerController.cpp:294] Completed Stage: Warm Up\n",
      "STAGE:2023-03-28 09:24:26 108:108 ActivityProfilerController.cpp:300] Completed Stage: Collection\n",
      "STAGE:2023-03-28 09:24:26 108:108 output_json.cpp:417] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
    "        model.record_thread_forward_backward_and_update(x, torch.nn.functional.one_hot(y, args.class_num).float())\n",
    "    prof.export_chrome_trace(f\"{dataset}_AL_P.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(dataset, max_len):\n",
    "    args = Args(dataset, max_len)\n",
    "    train_loader, test_loader, class_num, vocab = get_nlp_data(args)\n",
    "    args.class_num = class_num\n",
    "    args.pretrained_embedding = get_word_vector(vocab, 'glove')\n",
    "    model = TransformerAL(args.vocab_size, args.embedding_dim, args.x_hid, args.class_num, args.y_hid, args.act, args.lr, args.n_heads, args.n_layers, args.dropout, args.pretrained_embedding)\n",
    "    set_device(model, ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'])\n",
    "    \n",
    "    alm = []\n",
    "    for _ in range(10):\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            y = torch.nn.functional.one_hot(labels, args.class_num).float()\n",
    "            model(inputs, y)\n",
    "            model.thread_backward_and_update()\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        alm.append(end-start)   \n",
    "        \n",
    "    al = []\n",
    "    for _ in range(10):\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            y = torch.nn.functional.one_hot(labels, args.class_num).float()\n",
    "            model(inputs, y)\n",
    "            model.backward()\n",
    "            model.update()\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        al.append(end-start) \n",
    "        \n",
    "    alp = []\n",
    "    for _ in range(10):\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            y = torch.nn.functional.one_hot(labels, args.class_num).float()\n",
    "            model.thread_forward_backward_and_update(inputs, y)\n",
    "        torch.cuda.synchronize()\n",
    "        end = time.time()\n",
    "        alp.append(end-start) \n",
    "        \n",
    "    print(f\"{dataset}_AL:{np.mean(al):.4f} ± {np.std(al):.4f}\")\n",
    "    print(f\"{dataset}_ALM:{np.mean(alm):.4f} ± {np.std(alm):.4f}\")\n",
    "    print(f\"{dataset}_ALP:{np.mean(alp):.4f} ± {np.std(alp):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|========================= Load data:ag_news ========================================================|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ag_news (/home/u3933826/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "Found cached dataset ag_news (/home/u3933826/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|========================= Preprocessing ============================================================|\n",
      "Original Data: 120000\n",
      "Valid Data: 120000\n",
      "total count words 102019\n",
      "vocab size 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading glove vocabs...: 100%|██████████| 400000/400000 [00:05<00:00, 71211.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 26754 words in glove\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:15<00:00, 29.37it/s]\n",
      "100%|██████████| 469/469 [00:15<00:00, 29.35it/s]\n",
      "100%|██████████| 469/469 [00:16<00:00, 29.27it/s]\n",
      "100%|██████████| 469/469 [00:16<00:00, 29.10it/s]\n",
      "100%|██████████| 469/469 [00:15<00:00, 29.47it/s]\n",
      "100%|██████████| 469/469 [00:15<00:00, 29.62it/s]\n",
      "100%|██████████| 469/469 [00:16<00:00, 28.33it/s]\n",
      "100%|██████████| 469/469 [00:17<00:00, 27.52it/s]\n",
      "100%|██████████| 469/469 [00:16<00:00, 28.57it/s]\n",
      "100%|██████████| 469/469 [00:15<00:00, 29.68it/s]\n",
      "100%|██████████| 469/469 [00:20<00:00, 22.45it/s]\n",
      "100%|██████████| 469/469 [00:20<00:00, 22.86it/s]\n",
      "100%|██████████| 469/469 [00:20<00:00, 23.24it/s]\n",
      "100%|██████████| 469/469 [00:20<00:00, 23.19it/s]\n",
      "100%|██████████| 469/469 [00:20<00:00, 23.00it/s]\n",
      "100%|██████████| 469/469 [00:21<00:00, 21.49it/s]\n",
      "100%|██████████| 469/469 [00:20<00:00, 22.65it/s]\n",
      "100%|██████████| 469/469 [00:20<00:00, 22.88it/s]\n",
      "100%|██████████| 469/469 [00:20<00:00, 22.83it/s]\n",
      "100%|██████████| 469/469 [00:20<00:00, 22.60it/s]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.93it/s]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.09it/s]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.23it/s]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.15it/s]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.76it/s]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.01it/s]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.77it/s]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.68it/s]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.98it/s]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ag_news_AL:20.6552 ± 0.4432\n",
      "ag_news_ALM:16.1679 ± 0.3712\n",
      "ag_news_ALP:14.2381 ± 0.0741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timer('ag_news', 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|========================= Load data:imdb ===========================================================|\n",
      "|========================= Preprocessing ============================================================|\n",
      "Original Data: 40000\n",
      "Valid Data: 40000\n",
      "total count words 193263\n",
      "vocab size 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading glove vocabs...: 100%|██████████| 400000/400000 [00:05<00:00, 70021.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 27875 words in glove\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:09<00:00, 16.76it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 17.25it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 17.42it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 17.32it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 17.07it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.74it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 17.39it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 17.38it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.80it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 17.44it/s]\n",
      "100%|██████████| 157/157 [00:10<00:00, 15.22it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.57it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.15it/s]\n",
      "100%|██████████| 157/157 [00:10<00:00, 15.55it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.57it/s]\n",
      "100%|██████████| 157/157 [00:10<00:00, 15.34it/s]\n",
      "100%|██████████| 157/157 [00:10<00:00, 15.49it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.02it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.13it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.25it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.16it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 16.16it/s]\n",
      "100%|██████████| 157/157 [00:10<00:00, 15.24it/s]\n",
      "100%|██████████| 157/157 [00:10<00:00, 15.09it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 15.91it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 15.70it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 15.73it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 15.89it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 15.82it/s]\n",
      "100%|██████████| 157/157 [00:09<00:00, 15.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb_AL:9.8670 ± 0.2925\n",
      "imdb_ALM:9.1547 ± 0.1477\n",
      "imdb_ALP:9.9736 ± 0.2126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "timer('imdb', 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'dbpedia_14'\n",
    "args = Args(dataset, 128)\n",
    "train_loader, test_loader, class_num, vocab = get_nlp_data(args)\n",
    "args.class_num = class_num\n",
    "args.pretrained_embedding = get_word_vector(vocab, 'glove')\n",
    "model = TransformerAL(args.vocab_size, args.embedding_dim, args.x_hid, args.class_num, args.y_hid, args.act, args.lr, args.n_heads, args.n_layers, args.dropout, args.pretrained_embedding)\n",
    "set_device(model, ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2188/2188 [01:22<00:00, 26.53it/s]\n",
      "100%|██████████| 2188/2188 [01:20<00:00, 27.18it/s]\n",
      "100%|██████████| 2188/2188 [01:21<00:00, 26.71it/s]\n",
      "100%|██████████| 2188/2188 [01:18<00:00, 27.75it/s]\n",
      "100%|██████████| 2188/2188 [01:19<00:00, 27.39it/s]\n",
      "100%|██████████| 2188/2188 [01:23<00:00, 26.12it/s]\n",
      "100%|██████████| 2188/2188 [01:20<00:00, 27.10it/s]\n",
      "100%|██████████| 2188/2188 [01:22<00:00, 26.63it/s]\n",
      "100%|██████████| 2188/2188 [01:19<00:00, 27.51it/s]\n",
      "100%|██████████| 2188/2188 [01:21<00:00, 27.01it/s]\n"
     ]
    }
   ],
   "source": [
    "alm = []\n",
    "for _ in range(10):\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        y = torch.nn.functional.one_hot(labels, args.class_num).float()\n",
    "        model(inputs, y)\n",
    "        model.thread_backward_and_update()\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    alm.append(end-start)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2188/2188 [01:38<00:00, 22.12it/s]\n",
      "100%|██████████| 2188/2188 [01:49<00:00, 20.00it/s]\n",
      "100%|██████████| 2188/2188 [01:42<00:00, 21.40it/s]\n",
      "100%|██████████| 2188/2188 [01:34<00:00, 23.22it/s]\n",
      "100%|██████████| 2188/2188 [01:33<00:00, 23.36it/s]\n",
      "100%|██████████| 2188/2188 [01:32<00:00, 23.59it/s]\n",
      "100%|██████████| 2188/2188 [01:46<00:00, 20.59it/s]\n",
      "100%|██████████| 2188/2188 [01:42<00:00, 21.34it/s]\n",
      "100%|██████████| 2188/2188 [01:46<00:00, 20.53it/s]\n",
      "100%|██████████| 2188/2188 [01:49<00:00, 19.98it/s]\n"
     ]
    }
   ],
   "source": [
    "al = []\n",
    "for _ in range(10):\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        y = torch.nn.functional.one_hot(labels, args.class_num).float()\n",
    "        model(inputs, y)\n",
    "        model.backward()\n",
    "        model.update()\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    al.append(end-start)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbpedia_14_AL:101.6177 ± 6.1217\n",
      "dbpedia_14_ALM:81.0853 ± 1.4269\n"
     ]
    }
   ],
   "source": [
    "print(f\"{dataset}_AL:{np.mean(al):.4f} ± {np.std(al):.4f}\")\n",
    "print(f\"{dataset}_ALM:{np.mean(alm):.4f} ± {np.std(alm):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
